{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "97ed5ee7-1217-43d0-b84a-d7a8aa75f7b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ca95a7e5-6ed7-4bee-be53-c8910423172f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<module 'torch.version' from 'C:\\\\Users\\\\kyeon\\\\anaconda3\\\\Lib\\\\site-packages\\\\torch\\\\version.py'>\n"
     ]
    }
   ],
   "source": [
    "print(torch.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e311f8b8-9187-4ef4-83b3-2a45a0858ffb",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (3615966137.py, line 176)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[9], line 176\u001b[1;36m\u001b[0m\n\u001b[1;33m    e_model_and_plot_confusion_matrix(model, dataloaders['val'], class_names)\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m unexpected indent\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms, models\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import recall_score, confusion_matrix\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "# 데이터 전처리\n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.Resize((128, 128)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.Resize((128, 128)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "}\n",
    "data_dir = './final'\n",
    "image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x), data_transforms[x])\n",
    "                  for x in ['train', 'val']}\n",
    "dataloaders = {x: DataLoader(image_datasets[x], batch_size=16, shuffle=True, num_workers=4)\n",
    "               for x in ['train', 'val']}\n",
    "dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val']}\n",
    "class_names = image_datasets['train'].classes\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "# MobileNet 모델 불러오기 및 수정\n",
    "model = models.mobilenet_v2(pretrained=True)\n",
    "num_ftrs = model.classifier[1].in_features\n",
    "model.classifier[1] = nn.Linear(num_ftrs, len(class_names))\n",
    "model = model.to(device)\n",
    "# 학습 및 평가 함수\n",
    "def train_model(model, criterion, optimizer, start_epoch=0, num_epochs=10):\n",
    "    train_loss_history = []\n",
    "    val_loss_history = []\n",
    "    train_acc_history = []\n",
    "    val_acc_history = []\n",
    "    train_recall_history = []\n",
    "    val_recall_history = []\n",
    "    for epoch in range(start_epoch, start_epoch + num_epochs):\n",
    "        epoch_str = f'Epoch {epoch}/{start_epoch + num_epochs - 1}'\n",
    "        print(epoch_str)\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()\n",
    "            else:\n",
    "                model.eval()\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "            all_preds = []\n",
    "            all_labels = []\n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "                optimizer.zero_grad()\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    loss = criterion(outputs, labels)\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "                all_preds.extend(preds.cpu().numpy())\n",
    "                all_labels.extend(labels.cpu().numpy())\n",
    "                # GPU 메모리 정리\n",
    "                del inputs, labels, outputs, preds\n",
    "                torch.cuda.empty_cache()\n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
    "            epoch_recall = recall_score(all_labels, all_preds, average='macro')\n",
    "            if phase == 'train':\n",
    "                train_loss_history.append(epoch_loss)\n",
    "                train_acc_history.append(epoch_acc.item())\n",
    "                train_recall_history.append(epoch_recall)\n",
    "            else:\n",
    "                val_loss_history.append(epoch_loss)\n",
    "                val_acc_history.append(epoch_acc.item())\n",
    "                val_recall_history.append(epoch_recall)\n",
    "            log_str = f'{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f} Recall: {epoch_recall:.4f}'\n",
    "            print(log_str)\n",
    "        print()\n",
    "    return model, train_loss_history, val_loss_history, train_acc_history, val_acc_history, train_recall_history, val_recall_history\n",
    "# 하이퍼파라미터 값 범위 설정\n",
    "learning_rate_range = [0.0001, 0.0002, 0.0003]\n",
    "weight_decay_range = [0.003, 0.004, 0.005]\n",
    "dropout_range = [0.3, 0.4, 0.5]\n",
    "best_train_loss = float('inf')\n",
    "best_train_accuracy = 0\n",
    "best_hyperparams = {}\n",
    "for lr in learning_rate_range:\n",
    "    for wd in weight_decay_range:\n",
    "        for dropout in dropout_range:\n",
    "            print(f\"Training with learning rate: {lr}, weight decay: {wd}, dropout: {dropout}\")\n",
    "            # 모델 초기화\n",
    "            model = models.mobilenet_v2(pretrained=True)\n",
    "            num_ftrs = model.classifier[1].in_features\n",
    "            model.classifier[1] = nn.Linear(num_ftrs, len(class_names))\n",
    "            model = model.to(device)\n",
    "            optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=wd)\n",
    "            criterion = nn.CrossEntropyLoss()\n",
    "            model, train_loss_history, val_loss_history, train_acc_history, val_acc_history, train_recall_history, val_recall_history = train_model(\n",
    "                model, criterion, optimizer, start_epoch=0, num_epochs=30  )\n",
    "            avg_train_loss = sum(train_loss_history) / len(train_loss_history)\n",
    "            avg_train_accuracy = sum(train_acc_history) / len(train_acc_history)\n",
    "            if avg_train_loss < best_train_loss:\n",
    "                best_train_loss = avg_train_loss\n",
    "                best_train_accuracy = avg_train_accuracy\n",
    "                best_hyperparams = {'learning_rate': lr, 'weight_decay': wd, 'dropout': dropout}\n",
    "            print(f\"Learning rate: {lr}, Weight decay: {wd}, Dropout: {dropout} | Avg Train Loss: {avg_train_loss:.4f} | Avg Train Accuracy: {avg_train_accuracy:.4f}\")\n",
    "print(f\"Best hyperparameters: {best_hyperparams}\")\n",
    "print(f\"Best train loss: {best_train_loss:.4f}, Best train accuracy: {best_train_accuracy:.4f}\")\n",
    "# 시각화\n",
    "epochs = list(range(1, len(train_loss_history) + 1))\n",
    "# 학습 및 검증 손실 시각화\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(epochs, train_loss_history, label='Train Loss')\n",
    "plt.plot(epochs, val_loss_history, label='Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.show()\n",
    "# 학습 및 검증 정확도 시각화\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(epochs, train_acc_history, label='Train Accuracy')\n",
    "plt.plot(epochs, val_acc_history, label='Validation Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.show()\n",
    "# 학습 및 검증 리콜 시각화\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(epochs, train_recall_history, label='Train Recall')\n",
    "plt.plot(epochs, val_recall_history, label='Validation Recall')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Recall')\n",
    "plt.legend()\n",
    "plt.title('Training and Validation Recall')\n",
    "plt.show()\n",
    "# 모델 평가 및 혼동 행렬 계산 함수\n",
    "def evaluate_model_and_plot_confusion_matrix(model, dataloader, class_names):\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in dataloader:\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "    # 혼동 행렬 계산\n",
    "    cm = confusion_matrix(all_labels, all_preds)\n",
    "    # 비율로 변환\n",
    "    cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "    # 혼동 행렬 시각화\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(cm_normalized, annot=True, fmt=\".2f\", cmap=\"Blues\", xticklabels=class_names, yticklabels=class_names)\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.ylabel('True Label')\n",
    "    plt.title('Normalized Confusion Matrix')\n",
    "    plt.show()\n",
    "# 클래스 이름 설정\n",
    "class_names = ['battery', 'biological', 'cardboard', 'clothes', 'glass', 'metal', 'paper', 'plastic', 'shoes', 'trash']\n",
    "# 검증 데이터셋에 대해 혼동 행렬 계산 및 시각화\n",
    "evaluat\n",
    "  e_model_and_plot_confusion_matrix(model, dataloaders['val'], class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0dd05c5-f98c-4a45-b5b1-c42efcbb0cf3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
